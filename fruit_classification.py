# -*- coding: utf-8 -*-
"""Fruit_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yswvDwFI-DGsnTzrZJ2XU_CEeMZITs8O
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d moltean/fruits

from zipfile import ZipFile
dataset = '/content/fruits.zip'
with ZipFile(dataset, 'r') as zip:
  zip.extractall()
  print("Dataset Sucessfully extracted")

import os
path, dirs, files = next(os.walk('/content/fruits-360_dataset/fruits-360/Training'))
file_count = len(files)
print("Number of images in training dataset are: ", file_count)

base_dir = '/content/fruits-360_dataset/fruits-360'
train_dir = os.path.join(base_dir,  'Training')
test_dir = os.path.join(base_dir, 'Test')
for dirpath, dirnames, filenames in os.walk(train_dir):
    print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

import pandas as pd

base_dir = '/content/fruits-360_dataset/fruits-360'
train_dir = os.path.join(base_dir, 'Training')
validation_dir = os.path.join(base_dir, 'Test')

def create_dataframe(data_path):
    df = []
    for c in os.listdir(data_path):
        class_folder = os.path.join(data_path, c)
        for f in os.listdir(class_folder):
            f_path = os.path.join(class_folder, f)
            if f_path.endswith('jpg'):
                df.append([f_path, c])
    return pd.DataFrame(df, columns=('filename', 'class'))

classes = sorted([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])
df_train = create_dataframe(train_dir)
df_test = create_dataframe(validation_dir)

df_train, df_test

df_train.head()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split

df_train, df_val = train_test_split(df_train, test_size=0.3, random_state = 4)

df_train, df_val

def count_images(directory):
  total_images = 0
  for roots, dir, files in os.walk(directory):
    for file in files:
      if file.endswith('jpg') or file.endswith('png'):
        total_images += 1
  return total_images

df_train_count = count_images(train_dir)
df_test_count = count_images(test_dir)
print("Number of images in train directory = ", df_train_count)
print("Number of images in test directory = ", df_test_count)

import glob as gb

import pathlib
data_dir = pathlib.Path(train_dir)
class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))
print(class_names)

import PIL
fruits = list(data_dir.glob('Watermelon/*.jpg'))
plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    img = PIL.Image.open(str(fruits[i]))
    plt.imshow(img)
    plt.axis('off')

plt.show()

def count_images_per_class(directory):
    class_counts = {}
    for class_name in os.listdir(directory):
        class_path = os.path.join(directory, class_name)
        if os.path.isdir(class_path):
            class_counts[class_name] = len(os.listdir(class_path))
    return class_counts

train_class_count = count_images_per_class(train_dir)
sorted_class_counts = dict(sorted(train_class_count.items(), key=lambda item: item[1]))
top_10_classes = dict(list(sorted_class_counts.items())[-10:])
bottom_10_classes = dict(list(sorted_class_counts.items())[:10])
print("Top 10 classes:", list(top_10_classes.keys()))
print("Bottom 10 classes:", list(bottom_10_classes.keys()))

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.bar(top_10_classes.keys(), top_10_classes.values(), color='skyblue')
plt.title('Top 10 Class Distribution')
plt.xlabel('Class Labels')
plt.ylabel('Number of Images')
plt.xticks(rotation=90)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.bar(bottom_10_classes.keys(), bottom_10_classes.values(), color='skyblue')
plt.title('Bottom 10 Class Distribution')
plt.xlabel('Class Labels')
plt.ylabel('Number of Images')
plt.xticks(rotation=90)

import cv2
selected_image_paths = np.random.choice(list(data_dir.glob("Apple Braeburn/*.jpg")), 3, replace=False)
for image_path in selected_image_paths:
    image = cv2.imread(str(image_path))
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])
    plt.figure()
    plt.title('Histogram - {}'.format(image_path.name))
    plt.xlabel('Pixel Intensity')
    plt.ylabel('Frequency')
    plt.plot(hist)
    plt.show()

size = []
for folder in os.listdir(os.path.join(data_dir)):
    files = gb.glob(os.path.join(data_dir, folder, '*.jpg'))
    for file in files:
        image = plt.imread(file)
        size.append(image.shape)
size_counts = pd.Series(size).value_counts()
print(size_counts)
most_common_size = size_counts.idxmax()
print("Most common size:", most_common_size)

import random
def view_random_image(target_dir, target_class):
    target_folder = os.path.join(target_dir, target_class)
    random_image = random.choice(os.listdir(target_folder))
    img = mpimg.imread(os.path.join(target_folder, random_image))

    return img
rows = 20
cols = 7

plt.figure(figsize=(30, 30))
for i, class_name in enumerate(class_names):
    img = view_random_image(target_dir=data_dir, target_class=class_name)
    plt.subplot(rows, cols, i + 1)
    plt.imshow(img)
    plt.title(class_name)
    plt.axis("off")
plt.show()

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.layers import Dropout

train_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(
    df_train,
    target_size=(100, 100),
    batch_size=60,
    classes=classes,
    class_mode='categorical'
)
val_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(
    df_val,
    target_size=(100, 100),
    batch_size=75,
    classes=classes,
    class_mode='categorical',
    shuffle=False
)
test_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(
    df_test,
    target_size=(100, 100),
    batch_size=75,
    classes=classes,
    class_mode='categorical',
    shuffle=False
)
train_generator = train_gen
validation_generator = val_gen
test_generator = test_gen

(train_gen.classes)

y_test = test_generator.classes
y_test

train_gen.class_indices

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    keras.layers.Dropout(rate=0.5) ,
    Dense(131, activation='softmax')
])

from tensorflow.keras.metrics import Accuracy, Precision, Recall
from tensorflow.keras import backend as K

class F1Score(tf.keras.metrics.Metric):
    def __init__(self, name='f1_score', **kwargs):
        super(F1Score, self).__init__(name=name, **kwargs)
        self.precision = Precision()
        self.recall = Recall()

    def update_state(self, y_true, y_pred, sample_weight=None):
        self.precision.update_state(y_true, y_pred, sample_weight)
        self.recall.update_state(y_true, y_pred, sample_weight)

    def result(self):
        precision = self.precision.result()
        recall = self.recall.result()
        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))

    def reset_state(self):
        self.precision.reset_state()
        self.recall.reset_state()

metrics = [
    'accuracy',
    Precision(),
    Recall(),
    F1Score()
]

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=metrics)

model.fit(
    train_generator,
    steps_per_epoch=10,
    epochs=60,
    verbose=1,
    validation_data=validation_generator,
    validation_steps=8
)

model.save('model2.keras')

eval_result = model.evaluate(test_generator)

print("Test Accuracy:", eval_result[1] )
print("Test Loss:", eval_result[0] )
print("Test Precision:", eval_result[2] )
print("Test Recall:", eval_result[1] )
print("Test f1_score:", eval_result[1] )

from PIL import Image
from keras.preprocessing.image import img_to_array
def predict_image(img_path, model):
    fruits = train_generator.class_indices
    img = Image.open(img_path)
    img = img.resize((100, 100))
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)
    predicted_label = [k for k, v in fruits.items() if v == predicted_class][0]

    print("Prediction:", predicted_label)
    plt.imshow(img)
    plt.axis('off')
    plt.show()
predict_image('/content/fruits-360_dataset/fruits-360/Test/Avocado/47_100.jpg', model)

def grad_cam_heatmap(image, last_conv_layer_name='last_conv'):

    if model.layers[0].__class__.__name__ == 'Functional':
        last_conv_layer_idx = 0
        last_conv_layer_model = model.layers[0]
    else:
        last_conv_layer = model.get_layer(last_conv_layer_name)
        last_conv_layer_idx = model.layers.index(last_conv_layer)
        last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)


    classifier_input = tf.keras.Input(shape=last_conv_layer_model.output.shape[1:])
    x = classifier_input
    classifier_layers = model.layers[last_conv_layer_idx+1:]
    for layer in classifier_layers:
        x = layer(x)
    classifier_model = tf.keras.Model(classifier_input, x)


    with tf.GradientTape() as tape:
        last_conv_layer_output = last_conv_layer_model(image)
        tape.watch(last_conv_layer_output)
        preds = classifier_model(last_conv_layer_output)
        top_pred_index = tf.argmax(preds[0])
        top_class_channel = preds[:, top_pred_index]
    grads = tape.gradient(top_class_channel, last_conv_layer_output)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    last_conv_layer_output = last_conv_layer_output.numpy()[0]
    pooled_grads = pooled_grads.numpy()
    for i in range(pooled_grads.shape[-1]):
        last_conv_layer_output[:, :, i] *= pooled_grads[i]
    heatmap = np.mean(last_conv_layer_output, axis=-1)
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)

    return heatmap

def grad_cam_heatmap(img_path, model, last_conv_layer_name='last_conv'):
    img = cv2.imread(img_path)
    img = np.expand_dims(img, axis=0).astype('float32') / 255.0

    if model.layers[0].__class__.__name__ == 'Functional':
        last_conv_layer_idx = 0
        last_conv_layer_model = model.layers[0]
    else:
        last_conv_layer = model.get_layer(last_conv_layer_name)
        last_conv_layer_idx = model.layers.index(last_conv_layer)
        last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)

    classifier_input = tf.keras.Input(shape=last_conv_layer_model.output.shape[1:])
    x = classifier_input
    classifier_layers = model.layers[last_conv_layer_idx+1:]
    for layer in classifier_layers:
        x = layer(x)
    classifier_model = tf.keras.Model(classifier_input, x)

    with tf.GradientTape() as tape:
        last_conv_layer_output = last_conv_layer_model(img)
        tape.watch(last_conv_layer_output)
        preds = classifier_model(last_conv_layer_output)
        top_pred_index = tf.argmax(preds[0])
        top_class_channel = preds[:, top_pred_index]

    grads = tape.gradient(top_class_channel, last_conv_layer_output)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    last_conv_layer_output = last_conv_layer_output.numpy()[0]
    pooled_grads = pooled_grads.numpy()
    for i in range(pooled_grads.shape[-1]):
        last_conv_layer_output[:, :, i] *= pooled_grads[i]

    heatmap = np.mean(last_conv_layer_output, axis=-1)
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)

    return heatmap

def grad_cam(img_path, model, last_conv_layer_name='conv2d_2'):
    colors = plt.cm.jet(np.arange(256))[:, :3]
    gc_mask = grad_cam_heatmap(img_path, model, last_conv_layer_name)
    gc_mask_uint8 = (gc_mask*255.0).astype('uint8')
    heatmap = colors[gc_mask_uint8]
    img = cv2.imread(img_path).astype('uint8')
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    heatmap = (heatmap*255).astype('uint8')
    img_overlay = cv2.addWeighted(src1=img, alpha=0.6, src2=heatmap, beta=0.4, gamma=0.0)

    fig, ax = plt.subplots()
    im = ax.imshow(cv2.cvtColor(img_overlay, cv2.COLOR_BGR2RGB))

    cbar = ax.figure.colorbar(im, ax=ax)
    cbar.set_label('Activation')

    plt.show()

grad_cam('/content/fruits-360_dataset/fruits-360/Test/Avocado/88_100.jpg',model)

model.summary()

def f1_score(y_true, y_pred):
    precision = Precision()(y_true, y_pred)
    recall = Recall()(y_true, y_pred)
    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))

y_pred = model.predict(test_generator)

y_pred = np.argmax(y_pred, axis=1)

y_pred

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns
cm = confusion_matrix(y_test, y_pred)
TP = cm[1, 1]
FP = cm[0, 1]
TN = cm[0, 0]
FN = cm[1, 0]
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
print("True Positives (TP):", TP)
print("False Positives (FP):", FP)
print("True Negatives (TN):", TN)
print("False Negatives (FN):", FN)
print("Confusion Matrix:")
print(cm)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()
metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
metrics_values = [accuracy, precision, recall, f1]

plt.figure(figsize=(10, 6))
barplot = sns.barplot(x=metrics_values, y=metrics_names, palette="viridis")
plt.xlabel('Metric Value')
plt.title('Performance Metrics')
plt.xlim(0, 1)
for i, v in enumerate(metrics_values):
    barplot.text(v + 0.01, i, str(round(v, 2)), color='black', ha='left')

plt.show()

class_freq = {class_label: sum([1 for label in y_test if label == class_label]) for class_label in set(y_test)}
top_ten_classes = sorted(class_freq, key=class_freq.get, reverse=True)[:15]
top_ten_cm = cm[top_ten_classes][:, top_ten_classes]
top_ten_class_names = [class_names[class_label] for class_label in top_ten_classes]
plt.figure(figsize=(10, 8))
sns.heatmap(top_ten_cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix for Top 15 Frequent Classes')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.xticks(ticks=np.arange(15) + 0.5, labels=top_ten_class_names, rotation=45)
plt.yticks(ticks=np.arange(15) + 0.5, labels=top_ten_class_names, rotation=0)

plt.show()

!pip install streamlit

import streamlit as st

base = '/content/fruits-360_dataset/fruits-360'
train_dir = os.path.join(base, 'Training')
validation_dir = os.path.join(base, 'Test')
train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(100, 100),
    batch_size=60,
    class_mode='categorical'
)
validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(100, 100),
    batch_size=75,
    class_mode='categorical'
)
fruits = train_generator.class_indices
def load_saved_model():
    return load_model('model2.h5')


def preprocess_image(image):
    img = Image.open(image).convert('RGB')
    img = img.resize((100,100))
    img_array = np.array(img) / 255.0
    return img_array.reshape((-1, 100, 100, 3))

def predict(model, image):
    img_array = preprocess_image(image)
    prediction = model.predict(img_array)
    return prediction


# Streamlit app
def main():


    gradient_bg_css = """
        background: linear-gradient(to right, #4C0FB5, #198DD0);
        padding: 20px;
        border-radius: 10px;
        border: 4px solid white; /* Adding a 2px solid white border */
    """
    gradient_bg_css2 = """
        background: linear-gradient(to right, #4C0FB5, #198DD0);
        padding: 4px;
        border-radius: 5px;
        border: 3px solid white; /* Adding a 2px solid white border */
        font-size: 10px;
    """


    title_text = "<h1 style='text-align: center; color: white;'>Fruits Classification Web App</h1>"
    styled_= f"<div style='{gradient_bg_css}'>{title_text}</div>"


    st.write("")
    st.markdown(styled_, unsafe_allow_html=True)
    st.write("")
    st.write("")

    # Upload image
    uploaded_image = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

    if uploaded_image is not None:

        image = Image.open(uploaded_image)
        st.image(image, caption='Uploaded Image', use_column_width=True)
        st.markdown(
            """
            <style>
                .center {
                    display: flex;
                    justify-content: center;
                    align-items: center;
                }
                .main {
                    text-align: center;
                }
                h3{
                    font-size: 25px
                }
                .st-emotion-cache-16txtl3 h1 {
                font: bold 29px arial;
                text-align: center;
                margin-bottom: 15px

                }
                div[data-testid=stSidebarContent] {
                background-color: #111;
                border-right: 4px solid white;
                padding: 8px!important

                }

                div.block-containers{
                    padding-top: 0.7rem
                }

                .st-emotion-cache-z5fcl4{
                    padding-top: 5rem;
                    padding-bottom: 1rem;
                    padding-left: 1.1rem;
                    padding-right: 2.2rem;
                    overflow-x: hidden;
                }

                .st-emotion-cache-16txtl3{
                    padding: 2.7rem 0.6rem
                }

                .plot-container.plotly{
                    border: 0px solid white;
                    border-radius: 6px;
                }

                div.st-emotion-cache-1r6slb0 span.st-emotion-cache-10trblm{
                    font: bold 24px tahoma
                }
                div [data-testid=stImage]{
                    text-align: center;
                    display: block;
                    margin-left: auto;
                    margin-right: auto;
                    width: 100%;
                }

                div[data-baseweb=select]>div{
                    cursor: pointer;
                    background-color: #111;
                    border: 0px solid white;
                }
                div[data-baseweb=select]>div:hover{
                    border: 0px solid white

                }
                div[data-baseweb=base-input]{
                    background-color: #111;
                    border: 0px solid white;
                    border-radius: 5px;
                    padding: 5px
                }

                div[data-testid=stFormSubmitButton]> button{
                    width: 20%;
                    background-image: linear-gradient(to right, #6a11cb 0%, #2575fc 100%);
                    border: 3px solid white;
                    padding: 18px;
                    border-radius: 30px;
                    opacity: 0.8;
                }
                div[data-testid=stFormSubmitButton]  p{
                    font-weight: bold;
                    font-size : 20px
                }

                div[data-testid=stFormSubmitButton]> button:hover{
                    opacity: 3;
                    border: 2px solid white;
                    color: white
                }

            </style>
            """,
                unsafe_allow_html=True
            )
        st.write("")
        with st.form('form'):
            btn = st.form_submit_button('predict')
        if btn:
            st.write("")
            st.write("")
            st.write("")
            model = load_saved_model()
            prediction = predict(model, uploaded_image)
            top_5_indices = np.argsort(prediction[0])[::-1][:5]
            top_5_probs = prediction[0][top_5_indices]
            table_data = {'Class': [], 'Probability': []}
            for i in range(5):
                result = [k for k, v in fruits.items() if v == top_5_indices[i]][0]
                table_data['Class'].append(result)
                table_data['Probability'].append(top_5_probs[i])
            title_text = "<h3 style='text-align: center; color: white;'>Top 5 Predictions:</h3>"
            styled_title = f"<div style='{gradient_bg_css2}'>{title_text}</div>"
            st.write("")
            st.write("")
            st.write("")
            st.markdown(styled_title, unsafe_allow_html=True)
            table_style = "<style>th {background-image: linear-gradient(to right, #6a11cb 0%, #2575fc 100%); color: white;}</style>"
            st.write(table_style, unsafe_allow_html=True)
            st.write("")
            st.table(table_data)
            predicted_class = np.argmax(prediction)
            predicted_label = [k for k, v in fruits.items() if v == predicted_class][0]
            prediction_css = """
            background-color: white;
            color: blue;
            border: 2px solid blue;
            border-radius: 5px;
            padding: 10px;
            text-align: center;
            """
            st.write("")
            st.write("")
            st.markdown(
                f'<h3 style="{prediction_css}">Prediction:</h3>',
                unsafe_allow_html=True
            )
            st.write("")
            st.write("")
            st.write("")
            markdown_text = f'<spin style="color:lightgray;background:#575860;font-size:30px;border: 2px solid lightgray; padding: 10px;">{predicted_label}</spin>'
            st.markdown(markdown_text,unsafe_allow_html=True)

if __name__ == '__main__':
    main()